{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "\n",
    "############################\n",
    "#    hyper parameters      #\n",
    "############################\n",
    "\n",
    "# For separate margin loss\n",
    "flags.DEFINE_float('m_plus', 0.9, 'the parameter of m plus')\n",
    "flags.DEFINE_float('m_minus', 0.1, 'the parameter of m minus')\n",
    "flags.DEFINE_float('lambda_val', 0.5, 'down weight of the loss for absent digit classes')\n",
    "\n",
    "# for training\n",
    "flags.DEFINE_integer('batch_size', 10, 'batch size')\n",
    "flags.DEFINE_integer('seq_length', 60, 'seq_length')\n",
    "flags.DEFINE_integer('seq_start', 30, \"\"\" start of seq generation\"\"\")\n",
    "flags.DEFINE_integer('shape', 32, 'shape')\n",
    "flags.DEFINE_float('keep_prob', 0.8, 'for dropout')\n",
    "flags.DEFINE_integer('epoch', 50, 'epoch')\n",
    "flags.DEFINE_integer('iter_routing', 3, 'number of iterations in routing algorithm')\n",
    "flags.DEFINE_boolean('mask_with_y', True, 'use the true label to mask out target capsule or not')\n",
    "flags.DEFINE_integer('max_step', 5000, \"\"\"max num of steps\"\"\")\n",
    "flags.DEFINE_float('lr', 0.001, \"\"\"for dropout\"\"\")\n",
    "\n",
    "flags.DEFINE_float('weight_decay', 0.0005,  \"\"\" \"\"\")\n",
    "flags.DEFINE_float('weight_init', .1, \"\"\"weight init for fully connected layers\"\"\")\n",
    "flags.DEFINE_float('stddev', 0.01, 'stddev for W initializer')\n",
    "flags.DEFINE_float('regularization_scale', 0.392, 'regularization coefficient for reconstruction loss, default to 0.0005*784=0.392')\n",
    "\n",
    "\n",
    "############################\n",
    "#   environment setting    #\n",
    "############################\n",
    "flags.DEFINE_string('imagepath', 'G:\\\\SRAD\\\\SRAD2018_TRAIN_001', 'The pic path')\n",
    "flags.DEFINE_string('dataset', 'mnist', 'The name of dataset [mnist, fashion-mnist')\n",
    "flags.DEFINE_boolean('is_training', True, 'train or predict phase')\n",
    "flags.DEFINE_integer('num_threads', 8, 'number of threads of enqueueing examples')\n",
    "flags.DEFINE_string('logdir', 'logdir', 'logs directory')\n",
    "flags.DEFINE_integer('train_sum_freq', 100, 'the frequency of saving train summary(step)')\n",
    "flags.DEFINE_integer('val_sum_freq', 500, 'the frequency of saving valuation summary(step)')\n",
    "flags.DEFINE_integer('save_freq', 3, 'the frequency of saving model(epoch)')\n",
    "flags.DEFINE_string('results', 'results', 'path for saving results')\n",
    "flags.DEFINE_string('train_dir', './checkpoints/train_store_conv_lstm',\n",
    "                            \"\"\"dir to store trained net\"\"\")\n",
    "\n",
    "############################\n",
    "#   distributed setting    #\n",
    "############################\n",
    "flags.DEFINE_integer('num_gpu', 2, 'number of gpus for distributed training')\n",
    "flags.DEFINE_integer('batch_size_per_gpu', 15, 'batch size on 1 gpu')\n",
    "flags.DEFINE_integer('thread_per_gpu', 1, 'Number of preprocessing threads per tower.')\n",
    "\n",
    "cfg = tf.app.flags.FLAGS\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
